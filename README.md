<h1>DH1001 Individual Portfolio </h1>

<a title="Thelightang, Public domain, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Symbolic_Intelligence_in_AI_Systems.jpg"><img width="512" alt="descriptive image of an ai system, neural networks and the brain" src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Symbolic_Intelligence_in_AI_Systems.jpg/512px-Symbolic_Intelligence_in_AI_Systems.jpg?20250712123439"></a>

<h2> RESPONSE TO ANATOMY OF AN AI SYSTEM </h2>

 Before viewing this article, I was uncertain as to how technology and its internal functions would properly be conducted into running a  consistent and reliable means of technological aid for its respective user.  However, after reading the article, I found it very intriguing as too how much effort and precision is put into the foundations of an AI or Internet-sourced product. The Sierpinski Triangle offers a glimpse into the patterns and techniques required to ensure its natural resources and reliability can coincide with one another 24/7 either on an online status. 

 It its vital to represent how an internet/AI reliant product such as Alexa, gains its origin of information both factually and independently, and to ensure it is safely enabled to only listen in on its respective users requests, questions, etc. ,which is why it is deemed as one of the most convenient forms of household technology. However, the rapid rise in the usage of  internet sourced products is that the world could potentially become over-reliant on its fast paced response time and guaranteed answers, regardless of the subject being asked.

AI could become a hazard at times with regards to videos/photos seen in the media, in schools, etc, but I do solemnly think that there will need to be more technological effort and accuracy required for it to become a more global concern, as it offers assistance rather than danger. In conclusion, I found this article very interesting and detailed to its very last wire and I do very much look forward to the never-ending change to the world of technology we live in today.

<a title="Sage Ross, CC BY-SA 2.0 &lt;https://creativecommons.org/licenses/by-sa/2.0&gt;, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Aaron_Swartz_at_Boston_Wikipedia_Meetup,_2009-08-18.jpg"><img width="512" alt="Aaron Swartz at Boston Wikipedia Meetup, 2009-08-18" src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/bf/Aaron_Swartz_at_Boston_Wikipedia_Meetup%2C_2009-08-18.jpg/512px-Aaron_Swartz_at_Boston_Wikipedia_Meetup%2C_2009-08-18.jpg?20110720183749"></a>

<h3>THE INTERNET' S OWN BOY </h3> 

This film represents the mismanagement of public information and unprofessional practices, carried out by the four corners of the US Government, especially with the extreme measures and mistreatment of Aaron Swartz, not just on his mental state, but his own beliefs of the basic human right to read information publicly and freely online without any consequences . I was amazed by how at such a young age, Aaron was able to achieve so much that many young IT enthusiast's can only dream of and to not only offer people a deeper insight into exploring information and reading articles online, but also give people the rights and opportunities to dive deeper into the digital world, be able to study and relish in their chosen fields and not have to be limited to the physical media that was considered biased during the early 2000's.

Listening to the close friends, family and attorneys who believed in Aaron Swartz's ideas obviously were deeply saddened and moved by his death, not just because of the pressures of the courts filings, arrest warrants and jail time being pushed up time and time again, but the fact that he was upheld and wrongly accused of downloading online files for his own self-interest, however this wasn't his true intention. His true intentions were always for the betterment of those around him in his work environment and throughout the digital world, that their voices were heard & that what the government were originally trying to do with the public's own personal information was wrong and unethical. It's truly upsetting and disgusting that Aaron was being made as an example by the punishing court that he was labelled as some fraud or faulty hacker, when throughout his whole life, it is stated that he just wanted to do right by the people, for the truth to be told and that he made a good impact on the world around him.  His death was a shock to the world, a young man with the idea to go beyond the basic fundamentals of computing and gaining information without limitation. He had a lot of silent battles caused by the disappointing justice system , Aaron was willing to do whatever it takes so that the people could speak freely, gain information freely and to live a life where learning goes beyond limitation, he was a soldier, who had to bite the bullet time and time again and should never be forgotten for his uncompromising stand for the right to learn freely and go beyond the basics.

His impact on the digital world will never be forgotten, with the presence of Reddit and JSTOR still operating today and the newly abided 'Aaron's Law' will be a testament to his passion and dedication to never be limited to the one book, to be able to learn without stoppage and to be able to voice your opinions on how to make the digital world a safer and transparent society.  A truly great mentor and example.


<a title="Martin Anderson, Michael West, MIT &lt;http://opensource.org/licenses/mit-license.php&gt;, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Files_(software)_2021.png"><img width="128" alt="The 2021 version of the logo for Files, a modern file manager for Windows." src="https://upload.wikimedia.org/wikipedia/commons/c/cd/Files_%28software%29_2021.png?20241228112026"></a>

<h4> SHOULD ALL ARCHIVES BE OPEN ACCESS? </h4>

After reading through István Rev's article, I really like how he speaks out about how archives have become mre dynamic and politically charged and how society in today's world demand for more open digital access to archival material, and not just the basics of scholars and researchers. Rev discusses how according to the Open Access movement, while it is a crucial element to the uncompromising stand for open archives, the limitations are scarce according to peoples human rights and transparency, as it also tackles other challenging laws such as privacy, national security, etc.

Thirdly, what I very much admired from this article also is Rev's several exampleshe uses to back up his own illustration about the tension that grows within the subject open access. For example, he refers to a Rwandan woman that asks about wanting her name removed from an online deportation archive, which raises questions about the legal vs moral responsibilities that are imposed on archive holders and who is given the right who's name is confidential or for display.

Overall, Rév argues that openness and digital access are very vital values, in relation to a democracy, and that these archives are compiled with sensitive information, that must be cautiously cared for. This management of a person's private information balances the public's own right to know with the right to be protected.

<h5>PRINCIPLES WITHIN "A CONTRACT OF THE WEB" </h5>

After reading upon both principles 5 and 8 and having listened to Eli Pariser's TED talk, hearing from Pariser's own viewpoint on how personal data and interaction with online platforms like Facebook, Instagram, Google, etc, have implemented their own algorithemetic personalisation for its respective user. While it may be beneficial for some, Eli stated it blinds us from the news and knowledge of the world that 'we need to understand rather than what we want to understand.'

I find this very descriptive in terms of how certain platforms isolate us to certain criteria that while we may consistently search on a frequent basis, is based on our own human interests and to not have any implementations to introduce us to trending topics or daily rotated news pieces or articles that may peak our interests to something more exclusive and intrguing to learn more about rather than the algorithmetic norm certain platforms use to disguise the more crucial information every human's self-interest are ignited by.

In relation to principles 5 and 8, they both possess very reasonable measures and viewpoints that should be implemented more into the introductory software of internet platforms such as Google, such as providing clear explanations of processes affecting people's data, provide control panels where users manage their own data and minimize data collection on what is relevant or irrelevant. These measures in particular I find would be more beneficial to the user, that their information is safely secure and not displayed to the general public or used as a means of display to promote the websites own 'positive outlook' from its users. 

Many platforms in today's world must become more transparent to their online communities so that they can be trusted with what relevant information is necessary for the platform's own policies and principles, that they coincide with each other and that overall every user has access to all forms of media, both personal and trending that could be useful for their own basic human knowledge and self-awareness of what is happening both in the real world and the digital world.


<a title="RaFaDa20631, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:FasilitasStasiun_FaceRecog.svg"><img width="64" alt="FasilitasStasiun FaceRecog" src="https://upload.wikimedia.org/wikipedia/commons/thumb/9/9a/FasilitasStasiun_FaceRecog.svg/64px-FasilitasStasiun_FaceRecog.svg.png?20240919124046"></a>
<h5> JOY BOULOAMWINI'S TED TALK</h5> 

After listening to Joy Bouolamwini's TED talk on Bias in algorithmetic software, we are able to understand that while Artificial Intelligence is becoming more manageable and self aware. Within this talk,  Joy specifically highlights the discriminatory aspect of AI and facial recognition. 

This clear example of unreliable, discriminatory and misinterpretted analylisation within the 'generic software' seems to set a bad image on how AI is being implented into computer software and the depth of how security-based technology is becoming very strict and unaware of the self-inflicting negatives it is imposing on itself.

Joy also stated that nearly up to 1 in 2 people in the U.S, particulary those who are involved in crimes, have their faces scanned by police, and how there is a limitation on the amount of criminals can be scanned and accounted for. . AI is intelligent based on its own self- knowledge and generative response abilities, however trying to implement this fast paced response unit into everyday activities and even further down the line into security quarated databases and algorithims, could become dangerous and poorly managed by those who are in control of it. Overall, I found Joy's TED very intriguing as to how algorithmetic software is becoming very biased and mismanaged, and that it needs to be fully re-developed on and to make sure that it is accurare, and dependable in times of algorithmetic practices.

<h6> BIBLIOGRAPHY </h6>
https://www.ted.com/talks/joy_buolamwini_how_i_m_fighting_bias_in_algorithms
https://anatomyof.ai/
https://www.youtube.com/watch?v=9vz06QO3UkQ&feature=youtu.be
https://contractfortheweb.org/
https://www.ted.com/talks/eli_pariser_beware_online_filter_bubbles
https://poetofcode.com/
https://www.youtube.com/watch?v=55q1PqukFTM
https://www.youtube.com/watch?v=XLP4YTpUpBI

